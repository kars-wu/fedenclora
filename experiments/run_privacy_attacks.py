"""
éšç§æ”»å‡»å®éªŒä¸»è„šæœ¬ - ä¿®å¤ç‰ˆ
è¯„ä¼°FedEncLoRAã€FedLoRFDPå’ŒFedLoRA-DPå¯¹å„ç§éšç§æ”»å‡»çš„é˜²å¾¡æ•ˆæœ

ä½¿ç”¨çœŸå®æ•°æ®é›†å’Œæœ‰æ•ˆçš„æ”»å‡»æ–¹æ³•
"""
import os
import sys
import json
import argparse
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Subset, ConcatDataset
from transformers import AutoModelForCausalLM, AutoTokenizer, get_linear_schedule_with_warmup
from peft import LoraConfig, get_peft_model, TaskType
import numpy as np
import random
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, field
from tqdm import tqdm
import copy

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from experiments.data_utils import (
    load_sst2_dataset, load_alpaca_dataset, load_wikitext_dataset,
    load_dataset_for_experiment, create_member_nonmember_split,
    partition_dataset_for_fl, insert_canary, create_dataloader, collate_fn
)
from experiments.llm_attacks import (
    LLMMembershipInferenceAttack,
    LLMAttributeInferenceAttack,
    LLMDataExtractionAttack,
    run_all_attacks,
    summarize_attack_results
)


@dataclass
class ExperimentConfig:
    """å®éªŒé…ç½®"""
    # æ¨¡å‹é…ç½®
    model_path: str = "/data/wuhao/model/Qwen2.5-3B-Instruct"
    
    # æ•°æ®é›†é…ç½®
    dataset: str = "sst2"  # sst2, alpaca, wikitext
    num_train_samples: int = 2000
    num_member_samples: int = 300
    num_non_member_samples: int = 300
    max_length: int = 128
    
    # LoRAé…ç½®
    lora_r: int = 8
    lora_alpha: int = 16
    lora_dropout: float = 0.05
    lora_target_modules: List[str] = field(default_factory=lambda: [
        "q_proj", "k_proj", "v_proj", "o_proj"
    ])
    
    # è®­ç»ƒé…ç½®
    num_clients: int = 3
    num_fl_rounds: int = 5
    local_epochs: int = 3
    batch_size: int = 4
    learning_rate: float = 2e-4
    weight_decay: float = 0.01
    
    # é˜²å¾¡é…ç½®
    dp_epsilon: float = 5.0
    dp_delta: float = 1e-5
    dp_max_grad_norm: float = 1.0
    
    # FedLoRFDPé…ç½®ï¼ˆä½ç§©åˆ†è§£+DPï¼‰
    lorf_rank: int = 4  # ä½ç§©åˆ†è§£çš„ç§©
    
    # æ”»å‡»é…ç½®
    attack_batch_size: int = 4
    
    # å…¶ä»–
    seed: int = 42
    device: str = "cuda:0"
    output_dir: str = "./attack_results"
    canary_text: str = "My secret password is: XYZ789ABC"


def set_seed(seed: int):
    """è®¾ç½®éšæœºç§å­"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)


def load_model(model_path: str, device: str) -> Tuple[nn.Module, AutoTokenizer]:
    """åŠ è½½åŸºç¡€æ¨¡å‹"""
    print(f"Loading model from {model_path}...")
    
    tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token
    
    model = AutoModelForCausalLM.from_pretrained(
        model_path,
        torch_dtype=torch.bfloat16,
        device_map=device,
        trust_remote_code=True
    )
    
    print(f"Model loaded. Parameters: {sum(p.numel() for p in model.parameters()):,}")
    
    return model, tokenizer


def add_lora_to_model(model: nn.Module, config: ExperimentConfig) -> nn.Module:
    """æ·»åŠ LoRAé€‚é…å™¨"""
    print("Adding LoRA adapters...")
    
    lora_config = LoraConfig(
        r=config.lora_r,
        lora_alpha=config.lora_alpha,
        lora_dropout=config.lora_dropout,
        target_modules=config.lora_target_modules,
        task_type=TaskType.CAUSAL_LM,
        bias="none"
    )
    
    model = get_peft_model(model, lora_config)
    
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    total_params = sum(p.numel() for p in model.parameters())
    print(f"Trainable: {trainable_params:,} / {total_params:,} ({100*trainable_params/total_params:.2f}%)")
    
    return model


def train_one_epoch(
    model: nn.Module,
    dataloader: DataLoader,
    optimizer: torch.optim.Optimizer,
    device: str,
    desc: str = "Training"
) -> float:
    """è®­ç»ƒä¸€ä¸ªepoch"""
    model.train()
    total_loss = 0
    num_batches = 0
    
    for batch in tqdm(dataloader, desc=desc, leave=False):
        input_ids = batch["input_ids"].to(device)
        attention_mask = batch["attention_mask"].to(device)
        labels = batch["labels"].to(device)
        
        optimizer.zero_grad()
        
        outputs = model(
            input_ids=input_ids,
            attention_mask=attention_mask,
            labels=labels
        )
        
        loss = outputs.loss
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
        num_batches += 1
    
    return total_loss / num_batches if num_batches > 0 else 0


def train_with_dp(
    model: nn.Module,
    dataloader: DataLoader,
    optimizer: torch.optim.Optimizer,
    device: str,
    max_grad_norm: float,
    noise_multiplier: float,
    desc: str = "Training with DP"
) -> float:
    """å¸¦å·®åˆ†éšç§çš„è®­ç»ƒ"""
    model.train()
    total_loss = 0
    num_batches = 0
    
    for batch in tqdm(dataloader, desc=desc, leave=False):
        input_ids = batch["input_ids"].to(device)
        attention_mask = batch["attention_mask"].to(device)
        labels = batch["labels"].to(device)
        
        optimizer.zero_grad()
        
        outputs = model(
            input_ids=input_ids,
            attention_mask=attention_mask,
            labels=labels
        )
        
        loss = outputs.loss
        loss.backward()
        
        # æ¢¯åº¦è£å‰ª
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)
        
        # æ·»åŠ å™ªå£°
        for param in model.parameters():
            if param.grad is not None:
                noise = torch.normal(
                    mean=0,
                    std=noise_multiplier * max_grad_norm,
                    size=param.grad.shape,
                    device=param.grad.device,
                    dtype=param.grad.dtype
                )
                param.grad += noise
        
        optimizer.step()
        
        total_loss += loss.item()
        num_batches += 1
    
    return total_loss / num_batches if num_batches > 0 else 0


def low_rank_decompose(tensor: torch.Tensor, rank: int) -> Tuple[torch.Tensor, torch.Tensor]:
    """
    ä½ç§©åˆ†è§£ï¼ˆSVDï¼‰
    å°†çŸ©é˜µ W åˆ†è§£ä¸º L @ Rï¼Œå…¶ä¸­ L: (m, r), R: (r, n)
    """
    if len(tensor.shape) != 2:
        return None, None
    
    try:
        U, S, Vh = torch.linalg.svd(tensor.float(), full_matrices=False)
        # å–å‰rankä¸ªå¥‡å¼‚å€¼
        r = min(rank, len(S))
        L = U[:, :r] @ torch.diag(torch.sqrt(S[:r]))
        R = torch.diag(torch.sqrt(S[:r])) @ Vh[:r, :]
        return L.to(tensor.dtype), R.to(tensor.dtype)
    except:
        return None, None


def train_with_lorf_dp(
    model: nn.Module,
    dataloader: DataLoader,
    optimizer: torch.optim.Optimizer,
    device: str,
    max_grad_norm: float,
    noise_multiplier: float,
    lorf_rank: int,
    desc: str = "Training with LoRF+DP"
) -> float:
    """
    FedLoRFDP: ä½ç§©åˆ†è§£ + å·®åˆ†éšç§
    
    1. è®¡ç®—æ¢¯åº¦
    2. å¯¹æ¢¯åº¦è¿›è¡Œä½ç§©åˆ†è§£
    3. åœ¨ä½ç§©åˆ†é‡ä¸Šæ·»åŠ DPå™ªå£°ï¼ˆå™ªå£°é‡æ›´å°ï¼‰
    4. é‡æ„æ¢¯åº¦å¹¶æ›´æ–°
    """
    model.train()
    total_loss = 0
    num_batches = 0
    
    for batch in tqdm(dataloader, desc=desc, leave=False):
        input_ids = batch["input_ids"].to(device)
        attention_mask = batch["attention_mask"].to(device)
        labels = batch["labels"].to(device)
        
        optimizer.zero_grad()
        
        outputs = model(
            input_ids=input_ids,
            attention_mask=attention_mask,
            labels=labels
        )
        
        loss = outputs.loss
        loss.backward()
        
        # å¯¹æ¯ä¸ªå‚æ•°çš„æ¢¯åº¦è¿›è¡Œä½ç§©åˆ†è§£å’ŒåŠ å™ª
        for name, param in model.named_parameters():
            if param.grad is not None and "lora" in name.lower():
                grad = param.grad
                original_shape = grad.shape
                
                # åªå¯¹2Dæ¢¯åº¦è¿›è¡Œä½ç§©åˆ†è§£
                if len(original_shape) == 2:
                    L, R = low_rank_decompose(grad, lorf_rank)
                    
                    if L is not None and R is not None:
                        # åœ¨ä½ç§©åˆ†é‡ä¸Šæ·»åŠ å™ªå£°ï¼ˆå™ªå£°é‡ä¸ä½ç§©ç»´åº¦ç›¸å…³ï¼Œæ›´å°ï¼‰
                        noise_scale = noise_multiplier * max_grad_norm / np.sqrt(lorf_rank)
                        
                        noise_L = torch.normal(
                            mean=0, std=noise_scale,
                            size=L.shape, device=L.device, dtype=L.dtype
                        )
                        noise_R = torch.normal(
                            mean=0, std=noise_scale,
                            size=R.shape, device=R.device, dtype=R.dtype
                        )
                        
                        L_noisy = L + noise_L
                        R_noisy = R + noise_R
                        
                        # é‡æ„æ¢¯åº¦
                        param.grad = (L_noisy @ R_noisy).to(param.grad.dtype)
                    else:
                        # åˆ†è§£å¤±è´¥ï¼Œä½¿ç”¨æ™®é€šDP
                        noise = torch.normal(
                            mean=0, std=noise_multiplier * max_grad_norm,
                            size=grad.shape, device=grad.device, dtype=grad.dtype
                        )
                        param.grad += noise
                else:
                    # é2Dæ¢¯åº¦ä½¿ç”¨æ™®é€šDP
                    noise = torch.normal(
                        mean=0, std=noise_multiplier * max_grad_norm,
                        size=grad.shape, device=grad.device, dtype=grad.dtype
                    )
                    param.grad += noise
        
        # æ¢¯åº¦è£å‰ª
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)
        
        optimizer.step()
        
        total_loss += loss.item()
        num_batches += 1
    
    return total_loss / num_batches if num_batches > 0 else 0


def federated_training(
    model: nn.Module,
    client_dataloaders: List[DataLoader],
    config: ExperimentConfig,
    defense_type: str = "none"
) -> nn.Module:
    """
    æ¨¡æ‹Ÿè”é‚¦è®­ç»ƒ
    
    Args:
        model: æ¨¡å‹
        client_dataloaders: å„å®¢æˆ·ç«¯çš„æ•°æ®åŠ è½½å™¨
        config: é…ç½®
        defense_type: "none", "dp", "lorf_dp", "encryption"
    """
    print(f"\n{'='*60}")
    print(f"Federated Training - Defense: {defense_type.upper()}")
    print(f"{'='*60}")
    
    device = config.device
    model = model.to(device)
    
    # DPå™ªå£°å‚æ•°
    noise_multiplier = 0.0
    if defense_type in ["dp", "lorf_dp"]:
        noise_multiplier = np.sqrt(2 * np.log(1.25 / config.dp_delta)) / config.dp_epsilon
        print(f"DP noise multiplier: {noise_multiplier:.4f}")
    
    for round_idx in range(config.num_fl_rounds):
        print(f"\n[Round {round_idx + 1}/{config.num_fl_rounds}]")
        
        round_losses = []
        
        for client_idx, client_loader in enumerate(client_dataloaders):
            # åˆ›å»ºä¼˜åŒ–å™¨
            optimizer = torch.optim.AdamW(
                model.parameters(),
                lr=config.learning_rate,
                weight_decay=config.weight_decay
            )
            
            # æœ¬åœ°è®­ç»ƒ
            for epoch in range(config.local_epochs):
                if defense_type == "dp":
                    loss = train_with_dp(
                        model, client_loader, optimizer, device,
                        config.dp_max_grad_norm, noise_multiplier,
                        desc=f"Client {client_idx+1} Epoch {epoch+1}"
                    )
                elif defense_type == "lorf_dp":
                    loss = train_with_lorf_dp(
                        model, client_loader, optimizer, device,
                        config.dp_max_grad_norm, noise_multiplier,
                        config.lorf_rank,
                        desc=f"Client {client_idx+1} Epoch {epoch+1}"
                    )
                else:  # none æˆ– encryption
                    loss = train_one_epoch(
                        model, client_loader, optimizer, device,
                        desc=f"Client {client_idx+1} Epoch {epoch+1}"
                    )
            
            round_losses.append(loss)
            print(f"  Client {client_idx + 1}/{len(client_dataloaders)}: Final Loss = {loss:.4f}")
        
        print(f"  Round Average Loss: {np.mean(round_losses):.4f}")
    
    return model


def evaluate_model_utility(
    model: nn.Module,
    test_loader: DataLoader,
    device: str
) -> Dict[str, float]:
    """è¯„ä¼°æ¨¡å‹æ•ˆç”¨ï¼ˆperplexityï¼‰"""
    model.eval()
    total_loss = 0
    num_batches = 0
    
    with torch.no_grad():
        for batch in test_loader:
            input_ids = batch["input_ids"].to(device)
            attention_mask = batch["attention_mask"].to(device)
            labels = batch["labels"].to(device)
            
            outputs = model(
                input_ids=input_ids,
                attention_mask=attention_mask,
                labels=labels
            )
            
            total_loss += outputs.loss.item()
            num_batches += 1
    
    avg_loss = total_loss / num_batches if num_batches > 0 else float('inf')
    perplexity = np.exp(avg_loss)
    
    return {
        "loss": avg_loss,
        "perplexity": perplexity
    }


def run_experiment(config: ExperimentConfig) -> Dict[str, Any]:
    """è¿è¡Œå®Œæ•´å®éªŒ"""
    set_seed(config.seed)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(config.output_dir, exist_ok=True)
    
    # åŠ è½½tokenizer
    print("\n" + "="*60)
    print("PRIVACY ATTACK EXPERIMENTS")
    print("="*60)
    
    _, tokenizer = load_model(config.model_path, config.device)
    
    # åŠ è½½æ•°æ®é›†
    print(f"\nLoading {config.dataset} dataset...")
    train_dataset, test_dataset = load_dataset_for_experiment(
        config.dataset,
        tokenizer,
        max_length=config.max_length,
        num_samples=config.num_train_samples
    )
    
    # åˆ›å»ºæˆå‘˜/éæˆå‘˜åˆ’åˆ†
    member_dataset, non_member_dataset = create_member_nonmember_split(
        train_dataset,
        test_dataset,
        member_size=config.num_member_samples,
        non_member_size=config.num_non_member_samples
    )
    
    # åˆ’åˆ†å®¢æˆ·ç«¯æ•°æ®ï¼ˆå‡åŒ€åˆ’åˆ†ï¼‰
    client_datasets = partition_dataset_for_fl(
        train_dataset,
        config.num_clients
    )
    
    # åœ¨ç¬¬ä¸€ä¸ªå®¢æˆ·ç«¯çš„æ•°æ®ä¸­æ’å…¥canary
    canary_client0_dataset, canary_text = insert_canary(
        client_datasets[0],  # åªåœ¨client0çš„æ•°æ®ä¸­æ’å…¥
        tokenizer,
        canary_text=config.canary_text,
        num_copies=10
    )
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    member_loader = create_dataloader(member_dataset, config.attack_batch_size, shuffle=False)
    non_member_loader = create_dataloader(non_member_dataset, config.attack_batch_size, shuffle=False)
    test_loader = create_dataloader(test_dataset, config.attack_batch_size, shuffle=False)
    
    # å±æ€§æ¨ç†æ”»å‡»æ•°æ®
    attr_train_size = int(len(train_dataset) * 0.7)
    attr_train_loader = create_dataloader(
        Subset(train_dataset, range(attr_train_size)),
        config.attack_batch_size, shuffle=False
    )
    attr_test_loader = create_dataloader(
        Subset(train_dataset, range(attr_train_size, len(train_dataset))),
        config.attack_batch_size, shuffle=False
    )
    
    # åˆ›å»ºå„å®¢æˆ·ç«¯çš„æ•°æ®åŠ è½½å™¨ï¼ˆå‡åŒ€åˆ†å¸ƒï¼‰
    client_loaders = [
        create_dataloader(canary_client0_dataset, config.batch_size, shuffle=True),  # Client 0å¸¦canary
        *[create_dataloader(ds, config.batch_size, shuffle=True) for ds in client_datasets[1:]]  # å…¶ä»–å®¢æˆ·ç«¯
    ]
    
    print(f"\nClient data distribution:")
    for i, loader in enumerate(client_loaders):
        print(f"  Client {i}: {len(loader.dataset)} samples")
    
    all_results = {}
    
    # ================================================================
    # å®éªŒ1: æ— é˜²å¾¡ (FedLoRA baseline)
    # ================================================================
    print("\n" + "="*60)
    print("Experiment 1: No Defense (FedLoRA)")
    print("="*60)
    
    base_model, _ = load_model(config.model_path, config.device)
    model_no_defense = add_lora_to_model(base_model, config)
    
    model_no_defense = federated_training(
        model_no_defense,
        client_loaders,
        config,
        defense_type="none"
    )
    
    utility_no_defense = evaluate_model_utility(model_no_defense, test_loader, config.device)
    print(f"Model Utility - Loss: {utility_no_defense['loss']:.4f}, PPL: {utility_no_defense['perplexity']:.2f}")
    
    attacks_no_defense = run_all_attacks(
        model_no_defense, tokenizer,
        member_loader, non_member_loader,
        attr_train_loader, attr_test_loader,
        config.device,
        defense_name="No Defense (FedLoRA)",
        canary_text=canary_text,
        client_loaders=client_loaders
    )
    
    all_results["no_defense"] = {
        "utility": utility_no_defense,
        "attacks": attacks_no_defense,
        "summary": summarize_attack_results(attacks_no_defense)
    }
    
    del model_no_defense, base_model
    torch.cuda.empty_cache()
    
    # ================================================================
    # å®éªŒ2: FedLoRA-DP (å·®åˆ†éšç§)
    # ================================================================
    print("\n" + "="*60)
    print(f"Experiment 2: FedLoRA-DP (Îµ={config.dp_epsilon})")
    print("="*60)
    
    base_model, _ = load_model(config.model_path, config.device)
    model_dp = add_lora_to_model(base_model, config)
    
    model_dp = federated_training(
        model_dp,
        client_loaders,
        config,
        defense_type="dp"
    )
    
    utility_dp = evaluate_model_utility(model_dp, test_loader, config.device)
    print(f"Model Utility - Loss: {utility_dp['loss']:.4f}, PPL: {utility_dp['perplexity']:.2f}")
    
    attacks_dp = run_all_attacks(
        model_dp, tokenizer,
        member_loader, non_member_loader,
        attr_train_loader, attr_test_loader,
        config.device,
        defense_name=f"FedLoRA-DP (Îµ={config.dp_epsilon})",
        canary_text=canary_text,
        client_loaders=client_loaders
    )
    
    all_results["dp_defense"] = {
        "utility": utility_dp,
        "attacks": attacks_dp,
        "summary": summarize_attack_results(attacks_dp)
    }
    
    del model_dp, base_model
    torch.cuda.empty_cache()
    
    # ================================================================
    # å®éªŒ3: FedLoRFDP (ä½ç§©åˆ†è§£+å·®åˆ†éšç§) - è®ºæ–‡æå‡ºçš„æ–¹æ³•
    # ================================================================
    print("\n" + "="*60)
    print(f"Experiment 3: FedLoRFDP (rank={config.lorf_rank}, Îµ={config.dp_epsilon})")
    print("="*60)
    
    base_model, _ = load_model(config.model_path, config.device)
    model_lorf_dp = add_lora_to_model(base_model, config)
    
    model_lorf_dp = federated_training(
        model_lorf_dp,
        client_loaders,
        config,
        defense_type="lorf_dp"
    )
    
    utility_lorf_dp = evaluate_model_utility(model_lorf_dp, test_loader, config.device)
    print(f"Model Utility - Loss: {utility_lorf_dp['loss']:.4f}, PPL: {utility_lorf_dp['perplexity']:.2f}")
    
    attacks_lorf_dp = run_all_attacks(
        model_lorf_dp, tokenizer,
        member_loader, non_member_loader,
        attr_train_loader, attr_test_loader,
        config.device,
        defense_name=f"FedLoRFDP (r={config.lorf_rank}, Îµ={config.dp_epsilon})",
        canary_text=canary_text,
        client_loaders=client_loaders
    )
    
    all_results["lorf_dp_defense"] = {
        "utility": utility_lorf_dp,
        "attacks": attacks_lorf_dp,
        "summary": summarize_attack_results(attacks_lorf_dp)
    }
    
    del model_lorf_dp, base_model
    torch.cuda.empty_cache()
    
    # ================================================================
    # å®éªŒ4: FedEncLoRA (åŠ å¯†èšåˆ) - è®ºæ–‡æå‡ºçš„æ–¹æ³•
    # ================================================================
    print("\n" + "="*60)
    print("Experiment 4: FedEncLoRA (Encryption)")
    print("="*60)
    
    base_model, _ = load_model(config.model_path, config.device)
    model_enc = add_lora_to_model(base_model, config)
    
    # FedEncLoRAåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸æ™®é€šFedLoRAç›¸åŒ
    # ä½†å…¶å®‰å…¨æ€§æ¥è‡ªäºåŠ å¯†èšåˆï¼ŒæœåŠ¡å™¨æ— æ³•è·å–å•ä¸ªå®¢æˆ·ç«¯çš„æ›´æ–°
    # åœ¨æ”»å‡»è¯„ä¼°ä¸­ï¼Œæˆ‘ä»¬å‡è®¾æ”»å‡»è€…åªèƒ½è®¿é—®æœ€ç»ˆèšåˆçš„æ¨¡å‹
    model_enc = federated_training(
        model_enc,
        client_loaders,
        config,
        defense_type="encryption"
    )
    
    utility_enc = evaluate_model_utility(model_enc, test_loader, config.device)
    print(f"Model Utility - Loss: {utility_enc['loss']:.4f}, PPL: {utility_enc['perplexity']:.2f}")
    
    # æ³¨æ„ï¼šFedEncLoRAä¸»è¦é˜²å¾¡çš„æ˜¯æœåŠ¡å™¨ç«¯æ”»å‡»ï¼ˆä»å•ä¸ªå®¢æˆ·ç«¯æ›´æ–°æ¨æ–­ä¿¡æ¯ï¼‰
    # å¯¹äºæœ€ç»ˆæ¨¡å‹çš„æ”»å‡»ï¼ˆMIAã€AIAï¼‰ï¼ŒåŠ å¯†ä¸èƒ½æä¾›é¢å¤–ä¿æŠ¤
    # FedEncLoRAçš„ä¼˜åŠ¿åœ¨äºï¼š
    # 1. ä¸ä¼šå› ä¸ºåŠ å™ªè€ŒæŸå¤±æ¨¡å‹æ€§èƒ½ï¼ˆä¸DPç›¸æ¯”ï¼‰
    # 2. æœåŠ¡å™¨æ— æ³•åŒºåˆ†æˆ–åˆ†æå•ä¸ªå®¢æˆ·ç«¯çš„æ›´æ–°
    # æ¢¯åº¦æ³„éœ²æ”»å‡»å¯ä»¥å±•ç¤ºè¿™ä¸€ä¼˜åŠ¿
    attacks_enc = run_all_attacks(
        model_enc, tokenizer,
        member_loader, non_member_loader,
        attr_train_loader, attr_test_loader,
        config.device,
        defense_name="FedEncLoRA (Encryption)",
        canary_text=canary_text,
        client_loaders=None  # FedEncLoRA: æœåŠ¡å™¨æ— æ³•è®¿é—®å•ä¸ªå®¢æˆ·ç«¯æ›´æ–°ï¼Œè®¾ä¸ºNoneæ¨¡æ‹Ÿè¿™ç§æƒ…å†µ
    )
    
    all_results["encryption_defense"] = {
        "utility": utility_enc,
        "attacks": attacks_enc,
        "summary": summarize_attack_results(attacks_enc)
    }
    
    # ================================================================
    # ç»“æœæ±‡æ€»
    # ================================================================
    print("\n" + "="*60)
    print("RESULTS SUMMARY")
    print("="*60)
    
    print("\nğŸ“Š Model Utility Comparison:")
    print(f"  {'Defense':<30} {'Loss':>10} {'PPL':>10}")
    print(f"  {'-'*55}")
    for name, result in all_results.items():
        display_name = {
            "no_defense": "FedLoRA (No Defense)",
            "dp_defense": f"FedLoRA-DP (Îµ={config.dp_epsilon})",
            "lorf_dp_defense": f"FedLoRFDP (r={config.lorf_rank})",
            "encryption_defense": "FedEncLoRA"
        }.get(name, name)
        print(f"  {display_name:<30} {result['utility']['loss']:>10.4f} {result['utility']['perplexity']:>10.2f}")
    
    print("\nğŸ”’ Privacy Attack Comparison:")
    print("  (å¯¹äºMIA/AIA/Canary: è¶Šä½ = é˜²å¾¡è¶Šå¥½)")
    print("  (å¯¹äºGrad Leak: N/Aè¡¨ç¤ºæ”»å‡»è€…æ— æ³•è®¿é—®)")
    print(f"  {'Defense':<25} {'MIA AUC':>10} {'AIA Acc':>10} {'Canary':>10} {'Grad Leak':>12}")
    print(f"  {'-'*75}")
    for name, result in all_results.items():
        display_name = {
            "no_defense": "FedLoRA (No Defense)",
            "dp_defense": f"FedLoRA-DP (Îµ={config.dp_epsilon})",
            "lorf_dp_defense": f"FedLoRFDP (r={config.lorf_rank})",
            "encryption_defense": "FedEncLoRA"
        }.get(name, name)
        summary = result['summary']
        grad_leak = summary.get('gradient_privacy_leakage', None)
        grad_leak_str = f"{grad_leak:.4f}" if grad_leak is not None else "N/A (åŠ å¯†)"
        print(f"  {display_name:<25} {summary.get('mia_best_auc', 0.5):>10.4f} "
              f"{summary.get('aia_accuracy', 0.5):>10.4f} "
              f"{summary.get('canary_exposure', 0.5):>10.4f} "
              f"{grad_leak_str:>12}")
    
    # ä¿å­˜ç»“æœ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    result_file = os.path.join(config.output_dir, f"attack_results_{timestamp}.json")
    
    def convert_to_serializable(obj):
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, (np.integer, np.floating)):
            return float(obj)
        elif isinstance(obj, dict):
            return {k: convert_to_serializable(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [convert_to_serializable(v) for v in obj]
        return obj
    
    serializable_results = convert_to_serializable(all_results)
    
    with open(result_file, 'w') as f:
        json.dump(serializable_results, f, indent=2, ensure_ascii=False)
    
    print(f"\nâœ… Results saved to {result_file}")
    
    return all_results


def main():
    parser = argparse.ArgumentParser(description="Privacy Attack Experiments")
    
    parser.add_argument("--model-path", type=str, 
                       default="/data/wuhao/model/Qwen2.5-3B-Instruct")
    parser.add_argument("--dataset", type=str, default="sst2",
                       choices=["sst2", "alpaca", "wikitext"])
    parser.add_argument("--num-samples", type=int, default=2000)
    parser.add_argument("--num-clients", type=int, default=3)
    parser.add_argument("--num-rounds", type=int, default=5)
    parser.add_argument("--local-epochs", type=int, default=3)
    parser.add_argument("--batch-size", type=int, default=4)
    parser.add_argument("--dp-epsilon", type=float, default=5.0)
    parser.add_argument("--lorf-rank", type=int, default=4)
    parser.add_argument("--device", type=str, default="cuda:0")
    parser.add_argument("--output-dir", type=str, default="./attack_results")
    parser.add_argument("--seed", type=int, default=42)
    
    args = parser.parse_args()
    
    config = ExperimentConfig(
        model_path=args.model_path,
        dataset=args.dataset,
        num_train_samples=args.num_samples,
        num_clients=args.num_clients,
        num_fl_rounds=args.num_rounds,
        local_epochs=args.local_epochs,
        batch_size=args.batch_size,
        dp_epsilon=args.dp_epsilon,
        lorf_rank=args.lorf_rank,
        device=args.device,
        output_dir=args.output_dir,
        seed=args.seed
    )
    
    run_experiment(config)


if __name__ == "__main__":
    main()
